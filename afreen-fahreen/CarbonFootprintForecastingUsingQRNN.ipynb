{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#To upload the file from desktop\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Nqa7tp2LRIHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classical RNN model"
      ],
      "metadata": {
        "id": "Ogig6a6gQn5w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLl2tqGJQlgm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload and read the data\n",
        "data = pd.read_csv('co2_mm_mlo.csv')\n",
        "print(data.head())\n",
        "\n",
        "# Extract relevant columns and handle missing values\n",
        "data_relevant = data[['year', 'month', 'average']]\n",
        "data_relevant['average'] = data_relevant['average'].replace(-9.99, None).ffill()\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "data_relevant['average_scaled'] = scaler.fit_transform(data_relevant[['average']])\n",
        "\n",
        "# Create sequences for RNN\n",
        "def create_sequences(data, sequence_length):\n",
        "    xs, ys = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        x = data[i:i+sequence_length]\n",
        "        y = data[i+sequence_length]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "sequence_length = 12\n",
        "X, y = create_sequences(data_relevant['average_scaled'].values, sequence_length)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(50, activation='relu', input_shape=(sequence_length, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make predictions for the next 12 months\n",
        "last_sequence = data_relevant['average_scaled'].values[-sequence_length:]\n",
        "input_sequence = last_sequence.reshape((1, sequence_length, 1))\n",
        "\n",
        "predictions = []\n",
        "for _ in range(12):\n",
        "    next_value = model.predict(input_sequence)[0][0]\n",
        "    predictions.append(next_value)\n",
        "    input_sequence = np.append(input_sequence[:, 1:, :], [[[next_value]]], axis=1)\n",
        "\n",
        "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
        "\n",
        "# Plot predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data_relevant['year'] + data_relevant['month']/12, data_relevant['average'], label='Actual')\n",
        "plt.plot(np.arange(2023, 2024, 1/12), predictions, label='Predicted')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO2 Levels')\n",
        "plt.title('CO2 Level Predictions for 2023 using RNN')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('Predicted CO2 levels for 2023 using RNN:', predictions.flatten())\n",
        "\n",
        "# Create input sequence from the last 12 months in the training data\n",
        "last_sequence = data_relevant['average_scaled'].values[-sequence_length:]\n",
        "input_sequence = last_sequence.reshape((1, sequence_length, 1))\n",
        "\n",
        "# Predict the next 12 months\n",
        "classical_predictions = []\n",
        "for _ in range(12):\n",
        "    next_value = model.predict(input_sequence)[0][0]\n",
        "    classical_predictions.append(next_value)\n",
        "    input_sequence = np.append(input_sequence[:, 1:, :], [[[next_value]]], axis=1)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "classical_predictions = scaler.inverse_transform(np.array(classical_predictions).reshape(-1, 1))\n",
        "\n",
        "# Print predictions\n",
        "print('Predicted CO2 levels for 2023:', classical_predictions.flatten())\n",
        "\n",
        "# Import necessary library for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list of months for 2023\n",
        "months = [f'2023-{i:02d}' for i in range(1, 13)]\n",
        "\n",
        "# Plot the predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(months, classical_predictions, marker='o', linestyle='-', color='b')\n",
        "plt.title('Predicted Monthly Average CO2 Levels for 2023 using RNN')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('CO2 Levels (ppm)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introducing Quantum Layers - Quantum RNN model"
      ],
      "metadata": {
        "id": "cR8k4QhCQsqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pennylane as qml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv('co2_mm_mlo.csv')\n",
        "print(data.head())\n",
        "\n",
        "# Extract relevant columns and handle missing values\n",
        "data_relevant = data[['year', 'month', 'average']]\n",
        "data_relevant['average'] = data_relevant['average'].replace(-9.99, None).ffill()\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "data_relevant['average_scaled'] = scaler.fit_transform(data_relevant[['average']])\n",
        "\n",
        "# Create sequences for RNN\n",
        "def create_sequences(data, sequence_length):\n",
        "    xs, ys = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        x = data[i:i+sequence_length]\n",
        "        y = data[i+sequence_length]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "sequence_length = 12\n",
        "X, y = create_sequences(data_relevant['average_scaled'].values, sequence_length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "# Define the quantum circuit and device\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "def quantum_circuit(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "weight_shapes = {\"weights\": (3, n_qubits)}\n",
        "qnode = qml.QNode(quantum_circuit, dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "\n",
        "class QuantumLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumLayer, self).__init__()\n",
        "        self.qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.qlayer(x)\n",
        "\n",
        "class HybridRNN(nn.Module):\n",
        "    def __init__(self, sequence_length, input_dim, hidden_dim, output_dim):\n",
        "        super(HybridRNN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim, n_qubits)\n",
        "        self.quantum = QuantumLayer()\n",
        "        self.fc2 = nn.Linear(n_qubits, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(1, batch_size, self.hidden_dim).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc1(out[:, -1, :])\n",
        "        out = self.quantum(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "sequence_length = 12\n",
        "input_dim = 1\n",
        "hidden_dim = 50\n",
        "output_dim = 1\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = HybridRNN(sequence_length, input_dim, hidden_dim, output_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "X_train, X_test, y_train, y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)\n",
        "\n",
        "# Train the model\n",
        "epochs = 1000\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_output = model(X_test)\n",
        "        val_loss = criterion(val_output, y_test)\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "    val_losses.append(val_loss.item())\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = criterion(model(X_test), y_test)\n",
        "print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "# Make predictions for 2023\n",
        "model.eval()\n",
        "last_sequence = torch.tensor(data_relevant['average_scaled'].values[-sequence_length:], dtype=torch.float32).view(1, -1, 1).to(device)\n",
        "predictions = []\n",
        "\n",
        "for _ in range(12):\n",
        "    with torch.no_grad():\n",
        "        next_value = model(last_sequence).item()\n",
        "    predictions.append(next_value)\n",
        "    last_sequence = torch.cat((last_sequence[:, 1:, :], torch.tensor(next_value).view(1, 1, 1).to(device)), dim=1)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
        "print('Predicted CO2 levels for 2023:', predictions.flatten())\n",
        "\n",
        "# Plot actual vs predicted CO2 levels\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data_relevant['year'] + data_relevant['month']/12, data_relevant['average'], label='Actual')\n",
        "plt.plot(np.arange(2023, 2024, 1/12), predictions, label='Predicted')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO2 Levels')\n",
        "plt.title('CO2 Level Predictions for 2023')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create a list of months for 2023\n",
        "months = [f'2023-{i:02d}' for i in range(1, 13)]\n",
        "\n",
        "# Plot the predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(months, classical_predictions, marker='o', linestyle='-', color='b')\n",
        "plt.title('Predicted Monthly Average CO2 Levels for 2023 using QRNN')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('CO2 Levels (ppm)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Xy1PgyuQ3et"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}